function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 17-Jul-2019 11:45:58.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx6 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx5 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-4.56722362297114;-0.772919517349123;-10.9936531437561;-2.26050777353845;-3.21606542020163;-0.757340115201751];
x1_step1.gain = [0.490993949093478;0.197707415658338;0.157134609835059;0.197875164833028;0.368118963537917;1.4871117076737];
x1_step1.ymin = -1;

% Layer 1
b1 = [-1.902193668994096365;-1.713521436869336334;0.52282217715424572635;-0.45458739796927027932;-0.49992818072937511564;-0.83431970611346872868;0.2364216922754858452];
IW1_1 = [0.8411588495955566458 0.92448530011808704998 0.56573037272290038757 0.81609153156424896203 -0.55397972399943229416 -0.95289481933780562084;3.5837143319495967653 -0.20392603662564709466 -0.072356657944512348113 -0.54503495028018433821 1.2286399103810248246 -0.022966356192375567136;0.9037971895155912927 -0.77311544439326740363 1.8174417818429520199 -1.0974157309404846128 0.81560722121241913118 -0.40202257303268368327;-5.0757371453279818141 -3.3474684023363168173 1.0936757744553049498 3.372349618201065713 3.8250658442113345536 0.22791283439505605202;-1.1110749525169159035 -5.0491934660601067719 -1.361114220511555839 5.0627007408979309844 6.1995294919740357997 3.2509597039691930931;-1.5948684801571482161 0.38256993752044932133 1.6698060643705818773 -1.5962913732348702478 -2.1590504824022529462 -0.076067708882750675881;1.9812538972702358198 -2.0898278362335789282 -1.0247298285405184171 1.7700882837139593207 -4.1722981936958376536 -1.9293944608856854472];

% Layer 2
b2 = [-0.57480210864293668216;0.47853295883979474201;-0.054898915806782702664;0.59971064104131399652;-1.2410962876204238992];
LW2_1 = [0.52591006142881158159 3.7676018364876622257 -0.059468833413717447911 -0.18809404185856012925 -1.4857089135968033489 -0.9845607754328687955 -3.4119392955517735544;-0.59379681362945346823 -1.3296167055726326733 -0.021771163351099499794 -3.4054878091483877789 -3.9155881154002671884 1.8670273770028480431 1.1776980107334651393;-0.42229969916346338232 -0.28650418231249513701 -0.18116478440835026564 -3.7323247319945282996 -4.8343381864996946007 1.4780632006554352831 -0.010139895158910181353;-0.310794183996070561 -2.8942005446905905153 -0.040128621802512573491 3.1378325771287567392 4.8447021764606716943 0.68210713100174169554 1.5514598613802133009;-0.16108923660298621328 -0.63321479354052101485 0.001583322047138508229 3.455946535155236532 5.3788212345613883869 -2.0985362114967345271 -1.9840070679973131895];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
